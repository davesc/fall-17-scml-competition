{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import LSTM, Activation, Dense, BatchNormalization \n",
    "from keras.layers import TimeDistributed, SeparableConv2D, Conv2D, Input, Reshape\n",
    "from keras import backend as K\n",
    "from keras.applications.mobilenet import DepthwiseConv2D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "def _depthwise_conv_block_TimeDistributed(model, pointwise_conv_filters, alpha,\n",
    "                          depth_multiplier=1, strides=(1, 1), block_id=1):\n",
    "    \"\"\"this is rewritten from keras.applications.mobilenet, \n",
    "    using ConvLSTM2D and TimeDistributed depthwise convolution\n",
    "    Adds a depthwise convolution block.\n",
    "    \n",
    "    A depthwise convolution block consists of a depthwise conv,\n",
    "    batch normalization, relu6, pointwise convolution,\n",
    "    batch normalization and relu6 activation.\n",
    "    # Arguments\n",
    "        inputs: Input tensor of shape `(rows, cols, channels)`\n",
    "            (with `channels_last` data format) or\n",
    "            (channels, rows, cols) (with `channels_first` data format).\n",
    "        pointwise_conv_filters: Integer, the dimensionality of the output space\n",
    "            (i.e. the number output of filters in the pointwise convolution).\n",
    "        alpha: controls the width of the network.\n",
    "            - If `alpha` < 1.0, proportionally decreases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` > 1.0, proportionally increases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` = 1, default number of filters from the paper\n",
    "                 are used at each layer.\n",
    "        depth_multiplier: The number of depthwise convolution output channels\n",
    "            for each input channel.\n",
    "            The total number of depthwise convolution output\n",
    "            channels will be equal to `filters_in * depth_multiplier`.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "            Specifying any stride value != 1 is incompatible with specifying\n",
    "            any `dilation_rate` value != 1.\n",
    "        block_id: Integer, a unique identification designating the block number.\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, channels, rows, cols)` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(batch, rows, cols, channels)` if data_format='channels_last'.\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
    "        `rows` and `cols` values might have changed due to stride.\n",
    "    # Returns\n",
    "        Output tensor of block.\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "    \n",
    "#     #################\n",
    "#     model.add(ConvLSTM2D(filters=filtnum, kernel_size=(3, 3),\n",
    "#                    input_shape=(150, 64, 128, 1),\n",
    "#                    padding='same', return_sequences=True))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(1, 4, 4), padding='valid'))\n",
    "#     #############\n",
    "    \n",
    "    model.add(TimeDistributed(DepthwiseConv2D((3, 3),\n",
    "                        padding='same',\n",
    "                        depth_multiplier=depth_multiplier,\n",
    "                        strides=strides,\n",
    "                        use_bias=False),\n",
    "                        name='conv_dw_%d' % block_id))\n",
    "    model.add(TimeDistributed(BatchNormalization(axis=channel_axis), name='conv_dw_%d_bn' % block_id))\n",
    "    model.add(TimeDistributed(Activation(relu6), name='conv_dw_%d_relu' % block_id))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(pointwise_conv_filters, (1, 1),\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               strides=(1, 1)),\n",
    "               name='conv_pw_%d' % block_id))\n",
    "    model.add(TimeDistributed(BatchNormalization(axis=channel_axis), name='conv_pw_%d_bn' % block_id))\n",
    "    model.add(TimeDistributed(Activation(relu6), name='conv_pw_%d_relu' % block_id))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "alpha = 0.25 # alpha must be something like 1, .75, .5, .25\n",
    "depth_multiplier = 1\n",
    "channel_axis = 'channels_first'\n",
    "start_filters = int(32*alpha)\n",
    "input_shape = (150,64,128,1)\n",
    "output_shape = (150,54)\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(TimeDistributed(Conv2D(start_filters, (3,3), padding='same' , strides=(2,2)), input_shape=input_shape  ))\n",
    "_depthwise_conv_block_TimeDistributed(model, 64, alpha, depth_multiplier, block_id=1)\n",
    "\n",
    "_depthwise_conv_block_TimeDistributed(model, 128, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=2)\n",
    "_depthwise_conv_block_TimeDistributed(model, 128, alpha, depth_multiplier, block_id=3)\n",
    "\n",
    "_depthwise_conv_block_TimeDistributed(model, 256, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=4)\n",
    "_depthwise_conv_block_TimeDistributed(model, 256, alpha, depth_multiplier, block_id=5)\n",
    "\n",
    "_depthwise_conv_block_TimeDistributed(model, 512, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=6)\n",
    "_depthwise_conv_block_TimeDistributed(model, 512, alpha, depth_multiplier, block_id=7)\n",
    "_depthwise_conv_block_TimeDistributed(model, 512, alpha, depth_multiplier, block_id=8)\n",
    "_depthwise_conv_block_TimeDistributed(model, 512, alpha, depth_multiplier, block_id=9)\n",
    "_depthwise_conv_block_TimeDistributed(model, 512, alpha, depth_multiplier, block_id=10)\n",
    "_depthwise_conv_block_TimeDistributed(model, 512, alpha, depth_multiplier, block_id=11)\n",
    "\n",
    "_depthwise_conv_block_TimeDistributed(model, 1024, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=12)\n",
    "_depthwise_conv_block_TimeDistributed(model, 1024, alpha, depth_multiplier, block_id=13)\n",
    "\n",
    "model.add(Reshape((output_shape[0],-1)))\n",
    "model.add(LSTM(output_shape[1], return_sequences=True))\n",
    "model.add(BatchNormalization(momentum=0))\n",
    "model.add(Activation('softplus'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     model = Sequential()\n",
    "#     _conv_block(model,input_shape, 32, alpha, strides=(2, 2))\n",
    "#     model.summary()\n",
    "\n",
    "\n",
    "\n",
    "#     if include_top:\n",
    "#         if K.image_data_format() == 'channels_first':\n",
    "#             shape = (int(1024 * alpha), 1, 1)\n",
    "#         else:\n",
    "#             shape = (1, 1, int(1024 * alpha))\n",
    "\n",
    "#         x = GlobalAveragePooling2D()(x)\n",
    "#         x = Reshape(shape, name='reshape_1')(x)\n",
    "#         x = Dropout(dropout, name='dropout')(x)\n",
    "#         x = Conv2D(classes, (1, 1),\n",
    "#                    padding='same', name='conv_preds')(x)\n",
    "#         x = Activation('softmax', name='act_softmax')(x)\n",
    "#         x = Reshape((classes,), name='reshape_2')(x)\n",
    "#     else:\n",
    "#         if pooling == 'avg':\n",
    "#             x = GlobalAveragePooling2D()(x)\n",
    "#         elif pooling == 'max':\n",
    "#             x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "#     # Ensure that the model takes into account\n",
    "#     # any potential predecessors of `input_tensor`.\n",
    "#     if input_tensor is not None:\n",
    "#         inputs = get_source_inputs(input_tensor)\n",
    "#     else:\n",
    "#         inputs = img_input\n",
    "\n",
    "\n",
    "\n",
    "adamopt = keras.optimizers.Adam(lr = 0.001, decay = 1e-7)\n",
    "# Please make sure to use Poisson likelihood function for the loss function\n",
    "model.compile(optimizer=adamopt, loss='poisson')\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for the SMC competition for modeling neurons in the superior colliculus\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Please download the file SCNeuronModelCompetition.mat from here.\n",
    "# https://github.com/santacruzml/fall-17-scml-competition/releases/download/0.0-data/SCNeuronModelCompetition.mat\n",
    "\n",
    "datafile = h5py.File('SCNeuronModelCompetition.mat')\n",
    "movie = datafile.get('trainingmovie_mini') # movie for training\n",
    "frhist = datafile.get('FRhist_tr') # firing rate histograms\n",
    "\n",
    "def preprocess_movie(movie_in):\n",
    "    # trim the letterbox from the video\n",
    "    movie_out = np.array(movie_in[:,:,(16*128):(80*128)],dtype=np.uint8)\n",
    "    # reshape to original video frames\n",
    "    movie_out = np.reshape(movie_out,(288,150,64,128,1))\n",
    "    return movie_out\n",
    "\n",
    "movie = preprocess_movie(movie)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(movie, frhist, epochs=2, batch_size=4, validation_split=0.2, shuffle=True, callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('conv_lstm_dc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
