{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for the SMC competition for modeling neurons in the superior colliculus\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Please download the file SCNeuronModelCompetition.mat from here.\n",
    "# https://github.com/santacruzml/fall-17-scml-competition/releases/download/0.0-data/SCNeuronModelCompetition.mat\n",
    "\n",
    "datafile = h5py.File('/Users/dclark/work/scml17-data/SCNeuronModelCompetition.mat')\n",
    "movie = datafile.get('trainingmovie_mini') # movie for training\n",
    "frhist = datafile.get('FRhist_tr') # firing rate histograms\n",
    "\n",
    "# a little normalization for the movie (assuming that the movie is 3D array)\n",
    "def normalize(inputmovie):\n",
    "    movie_mean = np.mean(inputmovie, axis=(0, 1, 2))\n",
    "    movie_std = np.std(inputmovie, axis=(0, 1, 2))\n",
    "    return (inputmovie - movie_mean) / movie_std\n",
    "\n",
    "movie_norm = normalize(movie)\n",
    "\n",
    "movief = np.array(movie_norm[:,:,(16*128):(80*128)])\n",
    "movief = movief.reshape((288,150,64,128))\n",
    "movief = np.expand_dims(movief,axis=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movief = np.array(movie[:,:,(16*128):(80*128)],dtype='float32')\n",
    "movief = movief.reshape((288,150,64,128))\n",
    "movief = movief/255\n",
    "movief = np.expand_dims(movief,axis=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movief.dtype)\n",
    "print(movief.shape)\n",
    "print(frhist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frhist2 = frhist.astype(np.float32)\n",
    "# frhist  = np.expand_dims(frhist,axis=3)\n",
    "# print\n",
    "frhist2 = np.array(frhist,dtype='float32')\n",
    "frhist2 = np.expand_dims(frhist2,axis=3)\n",
    "print(frhist2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie, movie.shape)\n",
    "print(frhist.shape)\n",
    "\n",
    "# 150 is the number of frames\n",
    "# 12288 is the video pxiels, 96x128\n",
    "# 288 is the number of trials\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# frame = np.array(movie_norm[50,120,:]).reshape((96,128))\n",
    "# frame = np.array(movie[225,1,(0*128):(96*128)]).reshape((96,128))\n",
    "\n",
    "# print(frame.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(movief[225,1,:,:,:]),cmap='Greys_r',clim=(0,1))\n",
    "\n",
    "# for ii in enumerate frame[:,10]:\n",
    "#     print('{}:{} '.format(ii,frame[ii,10]))\n",
    "\n",
    "\n",
    "# frame2 = np.array(movie[225,1,(16*128):(80*128)]).reshape((64,128))\n",
    "# print(frame2.shape)\n",
    "# plt.figure()\n",
    "# plt.imshow(frame2,cmap='Greys_r',clim=(0,255))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = np.array(movie[225,1,:]).reshape((96,128))\n",
    "\n",
    "# print(frame2[:,60].shape)\n",
    "\n",
    "for a in zip(np.arange(frame2[:,55].shape[0]), frame2[:,110]):\n",
    "    print(a)\n",
    "    \n",
    "## the movie part is [16:80,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163840\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 150, 64, 128, 20)  15200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 150, 64, 128, 20)  80        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 150, 16, 32, 20)   0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 150, 10240)        0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 150, 54)           553014    \n",
      "=================================================================\n",
      "Total params: 568,294\n",
      "Trainable params: 568,254\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/10\n",
      "230/230 [==============================] - 34263s 149s/step - loss: 0.6921 - val_loss: 0.6729\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 1799s 8s/step - loss: 0.6226 - val_loss: 0.6645\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 1810s 8s/step - loss: 0.5973 - val_loss: 0.6658\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 1810s 8s/step - loss: 0.5999 - val_loss: 0.6557\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 2411s 10s/step - loss: 0.5811 - val_loss: 0.6533\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 24728s 108s/step - loss: 0.5788 - val_loss: 0.6377\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 1764s 8s/step - loss: 0.5828 - val_loss: 0.6426\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 1762s 8s/step - loss: 0.5772 - val_loss: 0.6322\n",
      "Epoch 9/10\n",
      "152/230 [==================>...........] - ETA: 9:48 - loss: 0.5895 "
     ]
    }
   ],
   "source": [
    "# here's the modeling part. I'll give just a starting point\n",
    "\n",
    "import keras\n",
    "# from keras.layers import LSTM, Activation, Dense, BatchNormalization\n",
    "from keras.layers import ConvLSTM2D, Dense, BatchNormalization, Flatten, Reshape, MaxPooling3D\n",
    "\n",
    "# It makes a 3-layer LSTM network with batch normalization on each layer.\n",
    "# No dropout, regularization, convolution structures are used.\n",
    "# As you see in the summary, most parameters go to the first weight matrix.\n",
    "\n",
    "\n",
    "\n",
    "movie_chunk_length = movief.shape[1]\n",
    "movie_pix = movief.shape[2]\n",
    "nHidden = 100\n",
    "nLayer = 3\n",
    "nSCNeu = frhist.shape[2]\n",
    "movie_i = 64\n",
    "movie_j = 128\n",
    "filtnum = 20\n",
    "\n",
    "print(movie_i*movie_j*filtnum)\n",
    "\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.convolutional import Conv3D\n",
    "# from keras.layers.convolutional_recurrent import n\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# import numpy as np\n",
    "# import pylab as plt\n",
    "\n",
    "# We create a layer which take as input movies of shape\n",
    "# (n_frames, width, height, channels) and returns a movie\n",
    "# of identical shape.\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(ConvLSTM2D(filters=filtnum, kernel_size=(3, 3),\n",
    "                   input_shape=(150, 64, 128, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 4, 4), padding='valid'))\n",
    "# model.add(ConvLSTM2D(filters=filtnum, kernel_size=(3, 3),\n",
    "#                    padding='same', return_sequences=True))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=None, padding='valid'))\n",
    "# model.add(ConvLSTM2D(filters=filtnum, kernel_size=(3, 3),\n",
    "#                    padding='same', return_sequences=True))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=None, padding='valid'))\n",
    "model.add(Reshape((150,-1)))\n",
    "# # model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(nSCNeu, activation='softmax'))\n",
    "model.compile(loss='poisson', optimizer='adadelta')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = keras.models.Sequential()\n",
    "# model.add(LSTM(nHidden, input_shape=(movie_chunk_length, movie_pix), return_sequences=True, implementation=2))\n",
    "\n",
    "# for _ in range(nLayer-1):\n",
    "#     model.add(BatchNormalization(momentum=0))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(LSTM(nHidden, return_sequences=True))\n",
    "    \n",
    "# model.add(BatchNormalization(momentum=0))\n",
    "# model.add(Activation('linear'))\n",
    "# model.add(Dense(nSCNeu))\n",
    "# model.add(Activation('softplus'))\n",
    "# adamopt = keras.optimizers.Adam(lr = 0.001, decay = 1e-7)\n",
    "\n",
    "# # Please make sure to use Poisson likelihood function for the loss function\n",
    "# model.compile(optimizer=adamopt, loss='poisson')\n",
    "model.summary()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(movief, frhist, epochs=10, batch_size=8, validation_split=0.2, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/Users/dclark/work/scml_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if it does a good job in the training dataset\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output = model.predict(movief)\n",
    "\n",
    "for m in range(0, 48):\n",
    "    n=31\n",
    "    # plot the average of 6 trials of the same movie\n",
    "    plt.plot(np.mean(frhist[(m*6):(m+1)*6, :, n], axis=(0)))\n",
    "    \n",
    "    # plot the output of the network\n",
    "    plt.plot(output[m*6,:,n])\n",
    "    plt.show()\n",
    "    # last 10 movies should be the validation dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movief3 = np.expand_dims(movief.reshape((288,150,64,128)),axis=4)\n",
    "movief3.shape\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(5)\n",
    "plt.imshow(np.squeeze(movief3[190,120,:,:,:]),cmap='Greys_r',clim=(0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_movies(n_samples=20, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
    "                              dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
    "                             y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the network to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1)**np.random.randint(0, 2)\n",
    "                    noisy_movies[i, t,\n",
    "                                 x_shift - w - 1: x_shift + w + 1,\n",
    "                                 y_shift - w - 1: y_shift + w + 1,\n",
    "                                 0] += noise_f * 0.1\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
    "                               y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "# Train the network\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((5,5),dtype='float')\n",
    "print(a.dtype)\n",
    "b = np.expand_dims(a,axis=2)\n",
    "print(b.shape)\n",
    "print(b)\n",
    "\n",
    "c = np.zeros((2, 3, 2, 2, 1))\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
